{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"London is the capital and most populous city of England and \n",
    "the United Kingdom.  Standing on the River Thames in the south east \n",
    "of the island of Great Britain, London has been a major settlement \n",
    "for two millennia. It was founded by the Romans, who named it Londinium.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London (GPE)\n",
      "England (GPE)\n",
      "the United Kingdom (GPE)\n",
      "the River Thames (LOC)\n",
      "the south east (LOC)\n",
      "Great Britain (GPE)\n",
      "London (GPE)\n",
      "two millennia (DATE)\n",
      "Romans (NORP)\n",
      "Londinium (ORG)\n"
     ]
    }
   ],
   "source": [
    "for entity in doc.ents: \n",
    "    print(f\"{entity.text} ({entity.label_})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_name_with_placeholder(token):\n",
    "    if token.ent_iob != 0 and token.ent_type_ == 'PERSON':\n",
    "        return \"[REDACTED]\"\n",
    "    else:\n",
    "        return token.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    In 1950, [REDACTED]published his famous article \"Computing Machinery and Intelligence\". In 1957, [REDACTED]’s \n",
      "Syntactic Structures revolutionized Linguistics with 'universal grammar', a rule based system of syntactic structures.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harshal/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: [W013] As of v2.1.0, Span.merge is deprecated. Please use the more efficient and less error-prone Doc.retokenize context manager instead.\n",
      "  \"\"\"\n",
      "/home/harshal/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: [W013] As of v2.1.0, Doc.merge is deprecated. Please use the more efficient and less error-prone Doc.retokenize context manager instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "def scrub(text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        ent.merge()\n",
    "    \n",
    "    tockens = map(replace_name_with_placeholder, doc)\n",
    "    return \"\".join(tockens)\n",
    "\n",
    "s = \"\"\"\n",
    "    In 1950, Alan Turing published his famous article \"Computing Machinery and Intelligence\". In 1957, Noam Chomsky’s \n",
    "Syntactic Structures revolutionized Linguistics with 'universal grammar', a rule based system of syntactic structures.\n",
    "\"\"\"\n",
    "\n",
    "print(scrub(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy.extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are things i know about london\n",
      " -the capital and most populous city of England and \n",
      "the United Kingdom.  \n",
      " -a major settlement \n",
      "for two millennia\n"
     ]
    }
   ],
   "source": [
    "statements = textacy.extract.semistructured_statements(doc, \"London\")\n",
    "\n",
    "print(\"Here are things i know about london\")\n",
    "\n",
    "for statement in statements:\n",
    "    subject, verb, fact = statement\n",
    "    print(f\" -{fact}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_chunks = textacy.extract.noun_chunks(doc, min_freq=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_chunks = map(str, noun_chunks)\n",
    "noun_chunks = map(str.lower, noun_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for noun_chunk in set(noun_chunks):\n",
    "    if len(noun_chunk.split(\" \")) > 1:\n",
    "        print(noun_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
